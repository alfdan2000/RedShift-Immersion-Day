# RedShift-Immersion-Day

Copyright 2019, Amazon Web Services, All Rights Reserved1Lab 2.4 Working with a 170GB Public Dataset (Global DB of Events, Language & Tone)In the previous labs, you worked with an extremly small dataset (less than < 10MB) and with a single data source. In this lab, let’s use a public dataset with bigger size and more tables and observe various services. The Global Database of Events, Language and Tone (GDELT) Project monitors the world's broadcast, print, and web news from nearly every corner of every country in over 100 languages and identifies the people, locations, organisations, counts, themes, sources, emotions, counts, quotes, images and events driving our global society every second of every day. The data set v1.0 is publicly available in S3 in the Registry of Open Data on AWS.In this lab, you will explore, catalogue, visualize, interact with this data using AWS services.The data set we will use contains (at the time to writing) thousands of uncompressed CSV files: hundreds of millions of lines, and is about 170GB. The Data format is defined here. The queries below are from Julien Simon’s blog.
Copyright 2019, Amazon Web Services, All Rights Reserved2You will use Athena to define columns you needed with the right type and point to the S3 bucket holding all files (in another AWS account). Athena will also be used in later labs to query data hosted in S3. 1.   Navigate to Athena in the console 2.   Enter the following HIVE DDL statement to create a database in glue metadata storeCREATE DATABASE gdelt;3.   Create a Table referring to the S3 bucket holding all files in the AWS account.a.   Before we proceed, a few remarks:i.   We are creating a schema definition in our Glue service, in our Data Catalogueii.   The actual data is in another AWS accountiii.   You can Access this data, because it is a public dataset located in 's3://gdelt-open-data/events/folder, and is open to everyone.iv.   Although we are creating TABLEs, there is no database. The events table is a representation of thousands of TSV (Tab Seperated Files) files stored in S3. Technologies like Apache HIVE and Presto enables accessing them using SQL like expressions.CREATE EXTERNAL TABLE IF NOT EXISTS gdelt.events (        `globaleventid` INT,        `day` INT,        `monthyear` INT,        `year` INT,        `fractiondate` FLOAT,        `actor1code` string,        `actor1name` string,        `actor1countrycode` string,        `actor1knowngroupcode` string,        `actor1ethniccode` string,        `actor1religion1code` string,        `actor1religion2code` string,        `actor1type1code` string,        `actor1type2code` string,        `actor1type3code` string,        `actor2code` string,        `actor2name` string,        `actor2countrycode` string,        `actor2knowngroupcode` string,        `actor2ethniccode` string,        `actor2religion1code` string,        `actor2religion2code` string,
